<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>metabolomics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="10.4_metabolomics_files/libs/clipboard/clipboard.min.js"></script>
<script src="10.4_metabolomics_files/libs/quarto-html/quarto.js"></script>
<script src="10.4_metabolomics_files/libs/quarto-html/popper.min.js"></script>
<script src="10.4_metabolomics_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="10.4_metabolomics_files/libs/quarto-html/anchor.min.js"></script>
<link href="10.4_metabolomics_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="10.4_metabolomics_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="10.4_metabolomics_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="10.4_metabolomics_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="10.4_metabolomics_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#multivariate-analysis-concepts-and-applications" id="toc-multivariate-analysis-concepts-and-applications" class="nav-link active" data-scroll-target="#multivariate-analysis-concepts-and-applications">ğŸ§ª Multivariate Analysis: Concepts and Applications</a>
  <ul class="collapse">
  <li><a href="#introduction-to-multivariate-analysis" id="toc-introduction-to-multivariate-analysis" class="nav-link" data-scroll-target="#introduction-to-multivariate-analysis">1. Introduction to Multivariate Analysis ğŸ“Š</a>
  <ul class="collapse">
  <li><a href="#exercise-1" id="toc-exercise-1" class="nav-link" data-scroll-target="#exercise-1"><strong>Exercise 1</strong></a></li>
  </ul></li>
  <li><a href="#principal-component-analysis-pca-the-unsupervised-explorer" id="toc-principal-component-analysis-pca-the-unsupervised-explorer" class="nav-link" data-scroll-target="#principal-component-analysis-pca-the-unsupervised-explorer">2. Principal Component Analysis (PCA): The Unsupervised Explorer ğŸ—ºï¸</a>
  <ul class="collapse">
  <li><a href="#exercise-2" id="toc-exercise-2" class="nav-link" data-scroll-target="#exercise-2"><strong>Exercise 2</strong></a></li>
  </ul></li>
  <li><a href="#step-1-visualizing-the-messy-raw-data" id="toc-step-1-visualizing-the-messy-raw-data" class="nav-link" data-scroll-target="#step-1-visualizing-the-messy-raw-data">Step 1: Visualizing the Messy Raw Data ğŸ“Š</a>
  <ul class="collapse">
  <li><a href="#whats-happening-here" id="toc-whats-happening-here" class="nav-link" data-scroll-target="#whats-happening-here">Whatâ€™s Happening Here? ğŸ¤”</a></li>
  <li><a href="#the-high-dimensional-challenge" id="toc-the-high-dimensional-challenge" class="nav-link" data-scroll-target="#the-high-dimensional-challenge">The High-Dimensional Challenge ğŸŒªï¸</a></li>
  </ul></li>
  <li><a href="#step-2-applying-pca" id="toc-step-2-applying-pca" class="nav-link" data-scroll-target="#step-2-applying-pca">Step 2: Applying PCA ğŸ§‘â€ğŸ”¬</a></li>
  <li><a href="#step-3-detecting-outliers-with-hotellings-tÂ²" id="toc-step-3-detecting-outliers-with-hotellings-tÂ²" class="nav-link" data-scroll-target="#step-3-detecting-outliers-with-hotellings-tÂ²">Step 3: Detecting Outliers with Hotellingâ€™s TÂ² ğŸš¨</a></li>
  <li><a href="#step-4-interpreting-the-pca-results" id="toc-step-4-interpreting-the-pca-results" class="nav-link" data-scroll-target="#step-4-interpreting-the-pca-results">Step 4: Interpreting the PCA Results ğŸ§©</a>
  <ul class="collapse">
  <li><a href="#exercise-2-1" id="toc-exercise-2-1" class="nav-link" data-scroll-target="#exercise-2-1"><strong>Exercise 2</strong></a></li>
  <li><a href="#learning-points" id="toc-learning-points" class="nav-link" data-scroll-target="#learning-points">Learning Points</a></li>
  </ul></li>
  <li><a href="#step-5-interpreting-the-pca-results" id="toc-step-5-interpreting-the-pca-results" class="nav-link" data-scroll-target="#step-5-interpreting-the-pca-results">Step 5: Interpreting the PCA Results ğŸ§©</a>
  <ul class="collapse">
  <li><a href="#exercise-2-2" id="toc-exercise-2-2" class="nav-link" data-scroll-target="#exercise-2-2"><strong>Exercise 2</strong></a></li>
  <li><a href="#learning-points-1" id="toc-learning-points-1" class="nav-link" data-scroll-target="#learning-points-1">Learning Points</a></li>
  </ul></li>
  <li><a href="#partial-least-squares-discriminant-analysis-pls-da-the-supervised-classifier" id="toc-partial-least-squares-discriminant-analysis-pls-da-the-supervised-classifier" class="nav-link" data-scroll-target="#partial-least-squares-discriminant-analysis-pls-da-the-supervised-classifier">3. Partial Least Squares Discriminant Analysis (PLS-DA): The Supervised Classifier ğŸ·ï¸</a>
  <ul class="collapse">
  <li><a href="#pls-da-in-action" id="toc-pls-da-in-action" class="nav-link" data-scroll-target="#pls-da-in-action">3.1 PLS-DA in Action</a></li>
  </ul></li>
  <li><a href="#bayesian-multivariate-models-embracing-uncertainty" id="toc-bayesian-multivariate-models-embracing-uncertainty" class="nav-link" data-scroll-target="#bayesian-multivariate-models-embracing-uncertainty">4. Bayesian Multivariate Models: Embracing Uncertainty ğŸŒˆ</a>
  <ul class="collapse">
  <li><a href="#bayesian-pca-with-pymc" id="toc-bayesian-pca-with-pymc" class="nav-link" data-scroll-target="#bayesian-pca-with-pymc">4.1 Bayesian PCA with PyMC</a></li>
  </ul></li>
  <li><a href="#machine-learning-a-quick-dip-into-random-forests" id="toc-machine-learning-a-quick-dip-into-random-forests" class="nav-link" data-scroll-target="#machine-learning-a-quick-dip-into-random-forests">5. Machine Learning: A Quick Dip into Random Forests ğŸŒ³</a>
  <ul class="collapse">
  <li><a href="#random-forest-classifier" id="toc-random-forest-classifier" class="nav-link" data-scroll-target="#random-forest-classifier">5.1 Random Forest Classifier</a></li>
  </ul></li>
  <li><a href="#using-principal-components-in-regression-biomarker-detection" id="toc-using-principal-components-in-regression-biomarker-detection" class="nav-link" data-scroll-target="#using-principal-components-in-regression-biomarker-detection">6. Using Principal Components in Regression: Biomarker Detection ğŸ”</a>
  <ul class="collapse">
  <li><a href="#pca-linear-regression" id="toc-pca-linear-regression" class="nav-link" data-scroll-target="#pca-linear-regression">6.1 PCA + Linear Regression</a></li>
  </ul></li>
  <li><a href="#summary-your-metabolomics-toolkit" id="toc-summary-your-metabolomics-toolkit" class="nav-link" data-scroll-target="#summary-your-metabolomics-toolkit">7. Summary: Your Metabolomics Toolkit ğŸ§°</a></li>
  </ul></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">




<section id="multivariate-analysis-concepts-and-applications" class="level1">
<h1>ğŸ§ª Multivariate Analysis: Concepts and Applications</h1>
<p>Welcome to this notebook on <strong>multivariate analysis</strong>!<br>
Multivariate methods are essential for exploring, modelling, and understanding complex datasets â€” where many variables interact simultaneously.</p>
<p>Weâ€™ll explore: - âœ¨ Key concepts of multivariate analysis - ğŸ§© Principal Component Analysis (PCA) - ğŸ¯ Partial Least Squares Discriminant Analysis (PLS-DA) - ğŸ“ˆ Bayesian multivariate models - ğŸ” Machine learning approaches to classification and prediction</p>
<p>As a practical example, weâ€™ll use a <strong>synthetic metabolomics dataset</strong>, similar to real-world studies, to illustrate the methods.<br>
However, the techniques you will learn apply just as well to fields like nutrition, clinical data, finance, or engineering!</p>
<p>Letâ€™s dive in! ğŸš€</p>
<hr>
<p>Before we start, letâ€™s set up the workspace, load the data and the necessary libraries:</p>
<details>
<summary>
Detailed description of libraries
</summary>
<section id="numpy" class="level4">
<h4 class="anchored" data-anchor-id="numpy">1. NumPy</h4>
<ul>
<li><strong>Purpose</strong>: NumPy is the foundational library for numerical computing in Python. It provides efficient array operations, mathematical functions, and linear algebra tools (e.g., matrix inversion, eigenvalues) used in data preprocessing and calculations like Hotellingâ€™s TÂ².</li>
<li><strong>Used For</strong>: Array manipulation, linear algebra (e.g., <code>la.inv</code> for inverse covariance in PCA), and mathematical operations.</li>
<li><strong>Documentation</strong>: <a href="https://numpy.org/doc/stable/">NumPy Documentation</a></li>
</ul>
</section>
<section id="pandas" class="level4">
<h4 class="anchored" data-anchor-id="pandas">2. Pandas</h4>
<ul>
<li><strong>Purpose</strong>: Pandas offers data structures (e.g., DataFrame) and tools for data manipulation and analysis, ideal for handling tabular data like datasets for PCA or machine learning.</li>
<li><strong>Used For</strong>: Data loading (e.g., CSV files), preprocessing, and feature engineering before PCA or PLS regression.</li>
<li><strong>Documentation</strong>: <a href="https://pandas.pydata.org/docs/">Pandas Documentation</a></li>
</ul>
</section>
<section id="scikit-learn-sklearn" class="level4">
<h4 class="anchored" data-anchor-id="scikit-learn-sklearn">3. Scikit-learn (sklearn)</h4>
<ul>
<li><strong>Purpose</strong>: Scikit-learn is a comprehensive machine learning library providing tools for data preprocessing, dimensionality reduction, regression, classification, and model evaluation.</li>
<li><strong>Used For</strong>:
<ul>
<li><code>StandardScaler</code>: Standardizing features for PCA or PLS regression.</li>
<li><code>PCA</code>: Dimensionality reduction for data visualization or analysis.</li>
<li><code>PLSRegression</code>: Partial Least Squares regression for predictive modeling.</li>
<li><code>train_test_split</code>: Splitting data into training and test sets.</li>
<li><code>accuracy_score</code>: Evaluating classification model performance.</li>
<li><code>RandomForestClassifier</code>: Building ensemble classification models.</li>
</ul></li>
<li><strong>Documentation</strong>: <a href="https://scikit-learn.org/stable/">Scikit-learn Documentation</a></li>
</ul>
</section>
<section id="matplotlib" class="level4">
<h4 class="anchored" data-anchor-id="matplotlib">4. Matplotlib</h4>
<ul>
<li><strong>Purpose</strong>: Matplotlib is a plotting library for creating static, interactive, and publication-quality visualizations, such as scatter plots or PCA biplots.</li>
<li><strong>Used For</strong>: Visualizing PCA results (e.g., scatter plots with Hotellingâ€™s TÂ² ellipses) or model performance metrics.</li>
<li><strong>Documentation</strong>: <a href="https://matplotlib.org/stable/">Matplotlib Documentation</a></li>
</ul>
</section>
<section id="pymc" class="level4">
<h4 class="anchored" data-anchor-id="pymc">5. PyMC</h4>
<ul>
<li><strong>Purpose</strong>: PyMC is a probabilistic programming library for Bayesian statistical modeling and inference, enabling flexible model specification and sampling.</li>
<li><strong>Used For</strong>: Building Bayesian models to estimate parameters or uncertainty, potentially for metabolomics or dietary data analysis.</li>
<li><strong>Documentation</strong>: <a href="https://www.pymc.io/">PyMC Documentation</a></li>
</ul>
</section>
<section id="arviz" class="level4">
<h4 class="anchored" data-anchor-id="arviz">6. ArviZ</h4>
<ul>
<li><strong>Purpose</strong>: ArviZ is a library for exploratory analysis of Bayesian models, providing tools for visualizing posterior distributions, convergence diagnostics, and model comparison.</li>
<li><strong>Used For</strong>: Analyzing and visualizing PyMC model outputs (e.g., trace plots, posterior predictive checks).</li>
<li><strong>Documentation</strong>: <a href="https://python.arviz.org/en/stable/">ArviZ Documentation</a></li>
</ul>
</section>
<section id="scipy" class="level4">
<h4 class="anchored" data-anchor-id="scipy">7. SciPy</h4>
<ul>
<li><strong>Purpose</strong>: SciPy builds on NumPy to provide advanced scientific computing tools, including statistical distributions, optimization, and signal processing.</li>
<li><strong>Used For</strong>: Statistical functions (e.g., <code>f.ppf</code> for F-distribution critical values in Hotellingâ€™s TÂ²) and linear algebra operations.</li>
<li><strong>Documentation</strong>: <a href="https://docs.scipy.org/doc/scipy/">SciPy Documentation</a></li>
</ul>
</section></details>
<div id="75548e9b" class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Setup for Google Colab: Fetch datasets automatically or manually</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> files</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the module and dataset for this notebook</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>MODULE <span class="op">=</span> <span class="st">'10_mini_projects'</span>  <span class="co"># e.g., '01_infrastructure'</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>DATASET <span class="op">=</span> <span class="st">'metabolomics_dataset.csv'</span>  <span class="co"># e.g., 'hippo_diets.csv'</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>BASE_PATH <span class="op">=</span> <span class="st">'/content/data-analysis-toolkit-FNS'</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>MODULE_PATH <span class="op">=</span> os.path.join(BASE_PATH, <span class="st">'notebooks'</span>, MODULE)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>DATASET_PATH <span class="op">=</span> os.path.join(<span class="st">'data'</span>, DATASET)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Attempt to clone the repository (automatic method)</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: If you encounter a cloning error (e.g., 'fatal: destination path already exists'),</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co">#       reset the runtime (Runtime &gt; Restart runtime) and run this cell again.</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Attempting to clone repository...'</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> os.path.exists(BASE_PATH):</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'Repository already exists, skipping clone.'</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        <span class="op">!</span>git clone https:<span class="op">//</span>github.com<span class="op">/</span>ggkuhnle<span class="op">/</span>data<span class="op">-</span>analysis<span class="op">-</span>toolkit<span class="op">-</span>FNS.git</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Debug: Print directory structure</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Listing repository contents:'</span>)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    <span class="op">!</span>ls {BASE_PATH}</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Listing notebooks directory contents:'</span>)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    <span class="op">!</span>ls {BASE_PATH}<span class="op">/</span>notebooks</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check if the module directory exists</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> os.path.exists(MODULE_PATH):</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">FileNotFoundError</span>(<span class="ss">f'Module directory </span><span class="sc">{</span>MODULE_PATH<span class="sc">}</span><span class="ss"> not found. Check the repository structure.'</span>)</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set working directory to the notebook's folder</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    os.chdir(MODULE_PATH)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Verify dataset is accessible</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> os.path.exists(DATASET_PATH):</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Dataset found: </span><span class="sc">{</span>DATASET_PATH<span class="sc">}</span><span class="ss"> ğŸ¦›'</span>)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Error: Dataset </span><span class="sc">{</span>DATASET<span class="sc">}</span><span class="ss"> not found after cloning.'</span>)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">FileNotFoundError</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Cloning failed: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Falling back to manual upload option...'</span>)</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 2: Manual upload option</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Please upload </span><span class="sc">{</span>DATASET<span class="sc">}</span><span class="ss"> manually.'</span>)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'1. Click the "Choose Files" button below.'</span>)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'2. Select </span><span class="sc">{</span>DATASET<span class="sc">}</span><span class="ss"> from your local machine.'</span>)</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'3. Ensure the file is placed in notebooks/</span><span class="sc">{</span>MODULE<span class="sc">}</span><span class="ss">/data/'</span>)</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create the data directory if it doesn't exist</span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>    os.makedirs(<span class="st">'data'</span>, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Prompt user to upload the dataset</span></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>    uploaded <span class="op">=</span> files.upload()</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check if the dataset was uploaded</span></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> DATASET <span class="kw">in</span> uploaded:</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> <span class="bu">open</span>(DATASET_PATH, <span class="st">'wb'</span>) <span class="im">as</span> f:</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>            f.write(uploaded[DATASET])</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Successfully uploaded </span><span class="sc">{</span>DATASET<span class="sc">}</span><span class="ss"> to </span><span class="sc">{</span>DATASET_PATH<span class="sc">}</span><span class="ss"> ğŸ¦›'</span>)</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">FileNotFoundError</span>(<span class="ss">f'Upload failed. Please ensure you uploaded </span><span class="sc">{</span>DATASET<span class="sc">}</span><span class="ss">.'</span>)</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a><span class="co"># Install required packages for this notebook</span></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install pandas numpy</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Python environment ready.'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="c3feb598" class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import necessary libraries</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cross_decomposition <span class="im">import</span> PLSRegression</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pymc <span class="im">as</span> pm</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> arviz <span class="im">as</span> az</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> f, chi2</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy.linalg <span class="im">as</span> la</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seaborn style for professional, clean visuals</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"whitegrid"</span>)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Load metabolomics dataset (1000 participants, 200 metabolites)</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'data/metabolomics_dataset.csv'</span>)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract features (metabolites) and labels</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.<span class="bu">filter</span>(like<span class="op">=</span><span class="st">'Metabolite_'</span>)  <span class="co"># Columns like 'Metabolite_1', ..., 'Metabolite_200'</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> df[<span class="st">'Label'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="introduction-to-multivariate-analysis" class="level2">
<h2 class="anchored" data-anchor-id="introduction-to-multivariate-analysis">1. Introduction to Multivariate Analysis ğŸ“Š</h2>
<p>Multivariate datasets - such as for example in metabolomics - are like a galaxy of stars âœ¨ â€” thousands of data, each twinkling with information. Multivariate analysis helps us find patterns, classify samples (e.g., healthy vs.&nbsp;diseased), and uncover biomarkers. These methods are essential because:</p>
<ul>
<li><strong>High-dimensionality</strong>: Metabolomics data often have more variables (metabolites) than samples.</li>
<li><strong>Correlations</strong>: Metabolites do not act in isolation; they interact in complex and structured ways.</li>
<li><strong>Noise</strong>: Biological and technical variability can obscure true signals.</li>
</ul>
<p>In this notebook, we will use Python with libraries such as <code>scikit-learn</code>, <code>PyMC</code>, and <code>pandas</code> to explore these techniques.<br>
If you are new to this area â€” no problem! Weâ€™ll guide you through each step. ğŸ˜Š</p>
<hr>
<section id="exercise-1" class="level3">
<h3 class="anchored" data-anchor-id="exercise-1"><strong>Exercise 1</strong></h3>
<p>Why do you think multivariate methods are better than analysing each metabolite separately?<br>
Write your thoughts below â€” no code needed, just reflect.</p>
<details>
<summary>
ğŸ’¡ Hint
</summary>
<p>Think about how metabolites might be connected through biological pathways, and why examining them together could reveal patterns that are invisible when looking at them one by one.</p>
</details>
</section>
</section>
<section id="principal-component-analysis-pca-the-unsupervised-explorer" class="level2">
<h2 class="anchored" data-anchor-id="principal-component-analysis-pca-the-unsupervised-explorer">2. Principal Component Analysis (PCA): The Unsupervised Explorer ğŸ—ºï¸</h2>
<p>PCA is like a treasure map for your data â€” it reduces dimensionality by finding <strong>principal components</strong> (PCs) that capture the greatest variance.<br>
In metabolomics, PCA helps us:</p>
<ul>
<li>Visualise sample similarities and groupings ğŸ§©</li>
<li>Detect outliers ğŸš¨</li>
<li>Explore underlying structure without using class labels (unsupervised)</li>
</ul>
<p>PCA projects high-dimensional data onto a smaller number of dimensions while preserving as much information as possible.<br>
It is often the first step in a metabolomics analysis to get a quick overview of the dataset.</p>
<p>We will implement PCA using <code>scikit-learn</code> and visualise the results with <code>matplotlib</code> and <code>seaborn</code>. ğŸ“ˆ</p>
<hr>
<section id="exercise-2" class="level3">
<h3 class="anchored" data-anchor-id="exercise-2"><strong>Exercise 2</strong></h3>
<p>Before we dive into the code, think about this:<br>
Why might PCA sometimes <em>hide</em> important biological information?</p>
<details>
<summary>
ğŸ’¡ Hint
</summary>
<p>PCA is optimised for variance, not necessarily for biological relevance. Sometimes important differences (e.g., between healthy and diseased) might not be the biggest source of variance!</p>
</details>
</section>
</section>
<section id="step-1-visualizing-the-messy-raw-data" class="level2">
<h2 class="anchored" data-anchor-id="step-1-visualizing-the-messy-raw-data">Step 1: Visualizing the Messy Raw Data ğŸ“Š</h2>
<p>Our dataset has 200 metabolites per participant, creating a high-dimensional maze. Direct visualization is nearly impossible (imagine a 200-dimensional scatter plot!). Instead, weâ€™ll use two techniques to show the dataâ€™s â€œmessinessâ€:</p>
<ul>
<li><strong>Correlation Heatmap</strong>: Reveals pairwise correlations between metabolites. High correlations suggest redundant features, a common issue in metabolomics that PCA can address.</li>
<li><strong>Pairwise Scatter Plots</strong>: Shows relationships between a subset of metabolites, highlighting how scattered and unstructured the raw data appears.</li>
</ul>
<p>These plots will demonstrate why we need PCA to simplify this complex dataset.</p>
<div id="da6ac0bb" class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize raw data: Correlation heatmap</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))  <span class="co"># Larger size for 200 metabolites</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>X_df <span class="op">=</span> df.<span class="bu">filter</span>(like<span class="op">=</span><span class="st">'Metabolite_'</span>)  <span class="co"># Ensure we use the DataFrame</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>corr <span class="op">=</span> X_df.corr()  <span class="co"># Compute pairwise correlations</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>sns.heatmap(corr, cmap<span class="op">=</span><span class="st">'coolwarm'</span>, center<span class="op">=</span><span class="dv">0</span>, vmin<span class="op">=-</span><span class="dv">1</span>, vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Correlation Heatmap of 200 Metabolites'</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="whats-happening-here" class="level3">
<h3 class="anchored" data-anchor-id="whats-happening-here">Whatâ€™s Happening Here? ğŸ¤”</h3>
<p>The heatmap shows correlations between our 200 metabolites. Notice the dense patterns of red (positive) and blue (negative) correlations â€” this redundancy makes the data â€œmessyâ€ and hard to interpret. Many metabolites move together, suggesting we can reduce dimensions without losing much information.</p>
<p>Next, letâ€™s try visualizing pairs of metabolites to see if patterns emerge naturally.</p>
<div id="8906b21b" class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize raw data: Pairwise scatter plots for top 5 metabolites</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>subset_cols <span class="op">=</span> df.<span class="bu">filter</span>(like<span class="op">=</span><span class="st">'Metabolite_'</span>).columns[:<span class="dv">5</span>]  <span class="co"># Select first 5 metabolite columns</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>sns.pairplot(df[subset_cols], diag_kind<span class="op">=</span><span class="st">'kde'</span>, plot_kws<span class="op">=</span>{<span class="st">'alpha'</span>: <span class="fl">0.5</span>})</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">'Pairwise Scatter Plots of Raw Metabolomics Data'</span>, y<span class="op">=</span><span class="fl">1.02</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="the-high-dimensional-challenge" class="level3">
<h3 class="anchored" data-anchor-id="the-high-dimensional-challenge">The High-Dimensional Challenge ğŸŒªï¸</h3>
<p>The scatter plots show relationships between just 5 of our 200 metabolites, and already itâ€™s chaotic! Points are scattered, with no clear groupings, and weâ€™re only seeing a tiny slice of the data. Imagine trying to plot all 200 dimensions â€” itâ€™s impossible! This messiness is why PCA is our go-to tool: it finds the directions (principal components) that capture the most variance, simplifying the data into a 2D map we can explore.</p>
<p>Before PCA, we need to preprocess the data to ensure fair comparisons</p>
<div id="0533b9e6" class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Preprocess: Standardize features to ensure equal scale</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="step-2-applying-pca" class="level2">
<h2 class="anchored" data-anchor-id="step-2-applying-pca">Step 2: Applying PCA ğŸ§‘â€ğŸ”¬</h2>
<p>Now that weâ€™ve seen the raw dataâ€™s complexity, letâ€™s apply PCA to reduce our 200 metabolites to 2 principal components (PCs). PCA identifies the directions of maximum variance, projecting our high-dimensional data onto a 2D plane. Weâ€™ll use <code>scikit-learn</code>â€™s <code>PCA</code> to do this efficiently.</p>
<p>Standardization (via <code>StandardScaler</code>) was critical to ensure metabolites with different scales (e.g., concentrations) donâ€™t skew the results. Letâ€™s transform the data and explore the results!</p>
<div id="393cf9e6" class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply PCA to reduce to 2 components</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>pca_result <span class="op">=</span> pca.fit_transform(X_scaled)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-3-detecting-outliers-with-hotellings-tÂ²" class="level2">
<h2 class="anchored" data-anchor-id="step-3-detecting-outliers-with-hotellings-tÂ²">Step 3: Detecting Outliers with Hotellingâ€™s TÂ² ğŸš¨</h2>
<p>PCA helps us spot outliers â€” samples that deviate significantly from the main data cloud. Weâ€™ll use <strong>Hotellingâ€™s TÂ²</strong>, a statistical test that measures how far each sample is from the center of the PCA scores, accounting for the dataâ€™s variance. Samples outside a 95% confidence ellipse are flagged as outliers.</p>
<p>Weâ€™ll compute TÂ² scores using <code>numpy.linalg</code> and <code>scipy.stats.chi2</code>, then visualize them in our PCA plot.</p>
<div id="77dfb0c9" class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure labels are numerical for plotting (if categorical, encode them)</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> labels.dtype <span class="op">==</span> <span class="st">'object'</span>:</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> pd.Categorical(labels).codes  <span class="co"># Convert to numerical codes (e.g., 0, 1)</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate Hotelling's T^2 for outlier detection</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>n_samples, n_components <span class="op">=</span> pca_result.shape</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>mean_scores <span class="op">=</span> np.mean(pca_result, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>cov_scores <span class="op">=</span> np.cov(pca_result.T)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure covariance matrix is well-conditioned</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> np.linalg.cond(cov_scores) <span class="op">&lt;</span> <span class="fl">1e6</span>:  <span class="co"># Check condition number</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    inv_cov <span class="op">=</span> la.inv(cov_scores)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add small diagonal for numerical stability</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    cov_scores <span class="op">+=</span> np.eye(n_components) <span class="op">*</span> <span class="fl">1e-6</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    inv_cov <span class="op">=</span> la.inv(cov_scores)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute T^2 scores</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>t2_scores <span class="op">=</span> np.array([</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    (pca_result[i] <span class="op">-</span> mean_scores).T <span class="op">@</span> inv_cov <span class="op">@</span> (pca_result[i] <span class="op">-</span> mean_scores)</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_samples)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Use chi-squared distribution for 95% confidence ellipse (simpler for 2D PCA)</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.05</span></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>critical_value <span class="op">=</span> chi2.ppf(<span class="dv">1</span> <span class="op">-</span> alpha, df<span class="op">=</span>n_components)  <span class="co"># Chi-squared with 2 degrees of freedom</span></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify outliers</span></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>outliers <span class="op">=</span> t2_scores <span class="op">&gt;</span> critical_value</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute ellipse for 95% confidence region</span></span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>eigenvalues, eigenvectors <span class="op">=</span> np.linalg.eig(cov_scores)</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>radii <span class="op">=</span> np.sqrt(critical_value <span class="op">*</span> eigenvalues)  <span class="co"># Scale by chi-squared critical value</span></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">2</span> <span class="op">*</span> np.pi, <span class="dv">100</span>)</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>ellipse <span class="op">=</span> (eigenvectors <span class="op">@</span> np.diag(radii) <span class="op">@</span> np.array([np.cos(theta), np.sin(theta)])).T <span class="op">+</span> mean_scores</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize PCA results with Hotelling's T^2 ellipse</span></span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>plt.scatter(pca_result[:, <span class="dv">0</span>], pca_result[:, <span class="dv">1</span>], c<span class="op">=</span>labels, cmap<span class="op">=</span><span class="st">'viridis'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, label<span class="op">=</span><span class="st">'Samples'</span>)</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>plt.scatter(pca_result[outliers, <span class="dv">0</span>], pca_result[outliers, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'red'</span>, s<span class="op">=</span><span class="dv">100</span>, marker<span class="op">=</span><span class="st">'x'</span>, label<span class="op">=</span><span class="st">'Outliers'</span>)</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>plt.plot(ellipse[:, <span class="dv">0</span>], ellipse[:, <span class="dv">1</span>], <span class="st">'k--'</span>, label<span class="op">=</span><span class="st">'95% Confidence Ellipse'</span>)</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'PC1'</span>)</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'PC2'</span>)</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'PCA of Metabolomics Data (1000 Participants) ğŸ—ºï¸'</span>)</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Print explained variance ratio and outlier count</span></span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Explained Variance Ratio: PC1 = </span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_[<span class="dv">0</span>]<span class="sc">:.2f}</span><span class="ss">, '</span></span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>      <span class="ss">f'PC2 = </span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_[<span class="dv">1</span>]<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Number of Outliers Detected: </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">sum</span>(outliers)<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-4-interpreting-the-pca-results" class="level2">
<h2 class="anchored" data-anchor-id="step-4-interpreting-the-pca-results">Step 4: Interpreting the PCA Results ğŸ§©</h2>
<p>Wow, look at that plot! Compared to the raw dataâ€™s chaos, PCA reveals clear groupings and outliers. The <strong>explained variance ratio</strong> tells us how much information PC1 and PC2 capture (e.g., 35% and 20%). Outliers outside the ellipse may indicate unusual samples, like measurement errors or unique biological profiles.</p>
<p>But PCA isnâ€™t perfect. Letâ€™s reflect on its limitations before moving forward.</p>
<hr>
<section id="exercise-2-1" class="level3">
<h3 class="anchored" data-anchor-id="exercise-2-1"><strong>Exercise 2</strong></h3>
<p>Why might PCA sometimes <em>hide</em> important biological information?</p>
<details>
<summary>
ğŸ’¡ Hint
</summary>
PCA is optimised for variance, not necessarily for biological relevance. Important differences (e.g., between healthy and diseased) might not be the biggest source of variance!
</details>
<hr>
</section>
<section id="learning-points" class="level3">
<h3 class="anchored" data-anchor-id="learning-points">Learning Points</h3>
<ul>
<li><strong>Raw Data Messiness</strong>: The heatmap and scatter plots showed high dimensionality and redundancy, making PCA essential.</li>
<li><strong>PCAâ€™s Power</strong>: PCA simplifies 200 metabolites into 2D, revealing patterns and outliers.</li>
<li><strong>Preprocessing Matters</strong>: Standardization ensures fair metabolite comparisons.</li>
<li><strong>Outlier Detection</strong>: Hotellingâ€™s TÂ² flags anomalies for further investigation.</li>
</ul>
<p><em>Ready to explore more of your dataâ€™s hidden treasures? Letâ€™s keep going! ğŸ§‘â€ğŸ”¬</em></p>
</section>
</section>
<section id="step-5-interpreting-the-pca-results" class="level2">
<h2 class="anchored" data-anchor-id="step-5-interpreting-the-pca-results">Step 5: Interpreting the PCA Results ğŸ§©</h2>
<p>Wow, look at that plot! Compared to the raw dataâ€™s chaos, PCA reveals clear groupings and outliers. The <strong>explained variance ratio</strong> tells us how much information PC1 and PC2 capture (e.g., 35% and 20%). Outliers outside the ellipse may indicate unusual samples, like measurement errors or unique biological profiles.</p>
<p>But PCA isnâ€™t perfect. Letâ€™s reflect on its limitations before moving forward.</p>
<hr>
<section id="exercise-2-2" class="level3">
<h3 class="anchored" data-anchor-id="exercise-2-2"><strong>Exercise 2</strong></h3>
<p>Why might PCA sometimes <em>hide</em> important biological information?</p>
<details>
<summary>
ğŸ’¡ Hint
</summary>
PCA is optimised for variance, not necessarily for biological relevance. Important differences (e.g., between healthy and diseased) might not be the biggest source of variance!
</details>
<hr>
</section>
<section id="learning-points-1" class="level3">
<h3 class="anchored" data-anchor-id="learning-points-1">Learning Points</h3>
<ul>
<li><strong>Raw Data Messiness</strong>: The heatmap and scatter plots showed high dimensionality and redundancy, making PCA essential.</li>
<li><strong>PCAâ€™s Power</strong>: PCA simplifies 200 metabolites into 2D, revealing patterns and outliers.</li>
<li><strong>Preprocessing Matters</strong>: Standardization ensures fair metabolite comparisons.</li>
<li><strong>Outlier Detection</strong>: Hotellingâ€™s TÂ² flags anomalies for further investigation.</li>
</ul>
<p><em>Ready to explore more of your dataâ€™s hidden treasures? Letâ€™s keep going! ğŸ§‘â€ğŸ”¬</em></p>
</section>
</section>
<section id="partial-least-squares-discriminant-analysis-pls-da-the-supervised-classifier" class="level2">
<h2 class="anchored" data-anchor-id="partial-least-squares-discriminant-analysis-pls-da-the-supervised-classifier">3. Partial Least Squares Discriminant Analysis (PLS-DA): The Supervised Classifier ğŸ·ï¸</h2>
<p>PLS-DA is like a guided missile ğŸ¯â€”itâ€™s supervised, meaning it uses class labels (e.g., â€œhealthyâ€ vs.&nbsp;â€œdiseasedâ€) to find components that maximize both variance and group separation. Perfect for classifying metabolomics samples!</p>
<section id="pls-da-in-action" class="level3">
<h3 class="anchored" data-anchor-id="pls-da-in-action">3.1 PLS-DA in Action</h3>
<p>Letâ€™s add class labels to our synthetic dataset and apply PLS-DA.</p>
<div id="2a1ac8a1" class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.<span class="bu">filter</span>(like<span class="op">=</span><span class="st">'Metabolite_'</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'Label'</span>]</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">11088</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>plsda <span class="op">=</span> PLSRegression(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>plsda.fit(X_train, y_train)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> plsda.transform(X)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>plt.scatter(scores[:, <span class="dv">0</span>], scores[:, <span class="dv">1</span>], c<span class="op">=</span>df[<span class="st">'Label'</span>], cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'PLS Component 1'</span>)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'PLS Component 2'</span>)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'PLS-DA of Metabolomics Data'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Explanation</strong>: - <strong>PLSRegression</strong>: Used for PLS-DA by treating class labels as continuous (threshold at 0.5 for binary classification). - <strong>train_test_split</strong>: Splits data to evaluate model performance. - <strong>Scores Plot</strong>: Shows how well PLS-DA separates classes.</p>
<p><strong>Exercise 3</strong>: Change <code>n_components</code> to 3 in the PLS-DA model. Does the accuracy improve? Why or why not?</p>
<details>
<summary>
ğŸ’¡ Hint
</summary>
More components capture more variance but may lead to overfitting, especially with small datasets. Check the accuracy and consider the trade-off!
</details>
<p><strong>Learn More</strong>: Explore <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6017634/">PLS-DA in metabolomics</a> for real-world applications! ğŸ§¬</p>
</section>
</section>
<section id="bayesian-multivariate-models-embracing-uncertainty" class="level2">
<h2 class="anchored" data-anchor-id="bayesian-multivariate-models-embracing-uncertainty">4. Bayesian Multivariate Models: Embracing Uncertainty ğŸŒˆ</h2>
<p>Bayesian methods are like a crystal ball ğŸ”®â€”they model uncertainty and let us build flexible multivariate models. In metabolomics, Bayesian approaches can handle missing data, model latent variables, or perform regression.</p>
<section id="bayesian-pca-with-pymc" class="level3">
<h3 class="anchored" data-anchor-id="bayesian-pca-with-pymc">4.1 Bayesian PCA with PyMC</h3>
<p>Letâ€™s use <code>PyMC</code> to implement a simple Bayesian PCA model. This assumes metabolites are generated from latent PCs with Gaussian noise.</p>
<p>Please be patient.</p>
<div id="8241b64e" class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.<span class="bu">filter</span>(like<span class="op">=</span><span class="st">'Metabolite_'</span>).values</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> bayes_pca:</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> pm.Normal(<span class="st">'z'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">1</span>, shape<span class="op">=</span>(<span class="dv">1000</span>, <span class="dv">2</span>))  <span class="co"># Latent PCs</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> pm.Normal(<span class="st">'w'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">1</span>, shape<span class="op">=</span>(<span class="dv">200</span>, <span class="dv">2</span>))  <span class="co"># Loadings</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> pm.math.dot(z, w.T)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    X_obs <span class="op">=</span> pm.Normal(<span class="st">'X'</span>, mu<span class="op">=</span>mu, sigma<span class="op">=</span><span class="fl">0.1</span>, observed<span class="op">=</span>X)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    trace <span class="op">=</span> pm.sample(<span class="dv">500</span>, return_inferencedata<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>az.plot_posterior(trace, var_names<span class="op">=</span>[<span class="st">'w'</span>], coords<span class="op">=</span>{<span class="st">'w_dim_0'</span>: [<span class="dv">0</span>]})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Explanation</strong>: - <strong>z</strong>: Latent PCs for each sample. - <strong>w</strong>: Loadings (how metabolites contribute to PCs). - <strong>X</strong>: Observed data modeled as a linear combination of PCs plus noise. - <strong>pm.sample</strong>: Uses MCMC to estimate posterior distributions.</p>
<p><strong>Exercise 4</strong>: Increase the number of samples (<code>500</code> to <code>1000</code>) in <code>pm.sample</code>. Does the posterior distribution change significantly? Why?</p>
<details>
<summary>
ğŸ’¡ Solution
</summary>
More samples improve the precision of the posterior but may not change the mean estimates much if the model has converged. Check the plot for tighter distributions!
</details>
<p><strong>Learn More</strong>: Dive into <a href="https://www.pymc.io/welcome.html">PyMCâ€™s documentation</a> for more Bayesian modeling ideas! ğŸ§ </p>
</section>
</section>
<section id="machine-learning-a-quick-dip-into-random-forests" class="level2">
<h2 class="anchored" data-anchor-id="machine-learning-a-quick-dip-into-random-forests">5. Machine Learning: A Quick Dip into Random Forests ğŸŒ³</h2>
<p>Machine learning (ML) is like a superpower for metabolomicsâ€”models like Random Forests can classify samples or identify important metabolites (potential biomarkers).</p>
<section id="random-forest-classifier" class="level3">
<h3 class="anchored" data-anchor-id="random-forest-classifier">5.1 Random Forest Classifier</h3>
<p>Letâ€™s use a Random Forest to classify our samples and find important metabolites.</p>
<div id="fd45a974" class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.<span class="bu">filter</span>(like<span class="op">=</span><span class="st">'Metabolite_'</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'Label'</span>]</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>rf <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">11088</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>rf.fit(X, y)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>importance <span class="op">=</span> rf.feature_importances_</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>plt.bar(<span class="bu">range</span>(<span class="dv">10</span>), importance[:<span class="dv">10</span>], tick_label<span class="op">=</span>X.columns[:<span class="dv">10</span>])</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Top 10 Metabolite Importances'</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Metabolite'</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Importance'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Explanation</strong>: - <strong>RandomForestClassifier</strong>: Builds multiple decision trees and aggregates their predictions. - <strong>feature_importances_</strong>: Shows which metabolites contribute most to classification (potential biomarkers!).</p>
<p><strong>Exercise 5</strong>: Increase <code>n_estimators</code> to 200. Does the accuracy improve? Plot the feature importances againâ€”are the top metabolites the same?</p>
<details>
<summary>
ğŸ’¡ Hint
</summary>
More trees reduce variance but may not change feature rankings much if the model is stable. Compare the plots visually!
</details>
<p><strong>Learn More</strong>: Check out <a href="https://scikit-learn.org/stable/modules/ensemble.html#forests-of-randomized-trees">Random Forests in scikit-learn</a> for more ML fun! ğŸš€</p>
</section>
</section>
<section id="using-principal-components-in-regression-biomarker-detection" class="level2">
<h2 class="anchored" data-anchor-id="using-principal-components-in-regression-biomarker-detection">6. Using Principal Components in Regression: Biomarker Detection ğŸ”</h2>
<p>Now, letâ€™s use PCA scores as predictors in a regression model to predict a continuous outcome (e.g., disease severity). This combines dimensionality reduction with predictive modeling.</p>
<section id="pca-linear-regression" class="level3">
<h3 class="anchored" data-anchor-id="pca-linear-regression">6.1 PCA + Linear Regression</h3>
<p>Weâ€™ll use the PCA scores from Section 2 and regress them against a synthetic outcome.</p>
<div id="bb23b5b2" class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.<span class="bu">filter</span>(like<span class="op">=</span><span class="st">'Metabolite_'</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'Severity'</span>]</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> StandardScaler().fit_transform(X)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>pca_result <span class="op">=</span> pca.fit_transform(X_scaled)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> LinearRegression()</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>lr.fit(pca_result, y)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> lr.predict(pca_result)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>plt.scatter(y, y_pred, c<span class="op">=</span><span class="st">'purple'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>plt.plot([y.<span class="bu">min</span>(), y.<span class="bu">max</span>()], [y.<span class="bu">min</span>(), y.<span class="bu">max</span>()], <span class="st">'r--'</span>)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'True Severity'</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Predicted Severity'</span>)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'PCA + Linear Regression'</span>)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'pca_regression.png'</span>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>plt.close()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Explanation</strong>: - <strong>pca_result</strong>: PCA scores (PCs) used as predictors. - <strong>LinearRegression</strong>: Models the relationship between PCs and the outcome. - <strong>Scatter Plot</strong>: Shows how well predictions match the true outcome.</p>
<p><strong>Exercise 6</strong>: Use only PC1 (<code>pca_result[:, 0].reshape(-1, 1)</code>) in the regression. Does the model perform worse? Why?</p>
<details>
<summary>
ğŸ’¡ Solution
</summary>
Using only PC1 reduces the information available to the model, likely worsening performance unless PC1 captures most of the relevant variation. Compare the scatter plots!
</details>
</section>
</section>
<section id="summary-your-metabolomics-toolkit" class="level2">
<h2 class="anchored" data-anchor-id="summary-your-metabolomics-toolkit">7. Summary: Your Metabolomics Toolkit ğŸ§°</h2>
<p>Hereâ€™s what youâ€™ve learned:</p>
<ul>
<li><strong>PCA</strong> ğŸ—ºï¸: Unsupervised, reduces dimensionality, explores data structure.</li>
<li><strong>PLS-DA</strong> ğŸ·ï¸: Supervised, classifies samples, maximizes group separation.</li>
<li><strong>Bayesian Models</strong> ğŸ”®: Handle uncertainty, flexible for complex problems.</li>
<li><strong>Random Forests</strong> ğŸŒ³: ML for classification and biomarker detection.</li>
<li><strong>PCA + Regression</strong> ğŸ”: Uses PCs for predictive modeling (e.g., disease severity).</li>
</ul>
<p><strong>Final Exercise</strong>: Pick a real metabolomics dataset (e.g., from <a href="https://www.ebi.ac.uk/metabolights/">MetaboLights</a>) and apply one of these methods. Share your findings in a short paragraph!</p>
<p><strong>Whatâ€™s Next?</strong> Try advanced methods like t-SNE, SVMs, or deep learning for metabolomics. Keep exploring, and happy analyzing! ğŸ˜„</p>
</section>


</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>